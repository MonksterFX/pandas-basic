{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipyleaflet\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Project: Chigago Taxi Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erste Schritte\n",
    "Mache dich mit der Struktur des Datensets vertraut. Öffne das Datenset <font color='orange'>bigdata/chigago/chigago.csv</font> und untersuche das Datenset mit den gelernten Methoden. Eine Kurzbeschreibung findest du unter im gleichen Ordner <font color='orange'>chigago_columns.txt</font>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../src/bigdata/chicago-taxi-trips/chicago_taxi_trips_2016_01.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hinzufügen von Taxiunternehmen, Long und Lat\n",
    "Die Informationen von Longitude und Latitude sind im Moment normalisiert. Das heißt wir müssen die Daten aus einer anderen Quelle erst verknüpfen. Wir brauchen für die weitere Auswertung nur die 'pickup' Koordinaten.\n",
    "\n",
    "**Die Dateien liegen als .json Datei vor. Auch JSON Dateien können mit Pandas importiert werden:**\n",
    "\n",
    "Für Longitude Latitude ist es notwendig den dtype auf float zu setzen, da sonst PANDAS denkt, es handle sich um ein Datum. Außerdem müssen wir für einen merge zwischen einem DataFrame und eine Series sicherstellen, das dieses einen Namen (dieser wird zum Spaltennamen) hat.\n",
    "\n",
    "```python\n",
    "s_beispiel = pd.read_json(<path to source>, typ='series', dtype='float')\n",
    "s_beispiel.name = 'beispiel' \n",
    "```\n",
    "\n",
    "Desweiteren wollen wir die Namen der Taxiunternehmen auf die selbe Weise importieren und verknüpfen.\n",
    "<hr>\n",
    "\n",
    "***Tipp: Alle Dateien befinden sich im Ordner Abschlussuebung***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prüfen ob der DataFrame vorher genauso lang ist wie nacher\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_long_pick = pd.read_json('pickup_longitude.json', typ='series', dtype='float')\n",
    "s_long_pick.name = 'pickup_longitude_clean'\n",
    "df = pd.merge(df, s_long_pick, how='left', left_on=['pickup_longitude'], right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_lat_pick = pd.read_json('pickup_latitude.json', typ='series', dtype='float')\n",
    "s_lat_pick.name = 'pickup_latitude_clean'\n",
    "df = pd.merge(df, s_lat_pick, how='left', left_on=['pickup_latitude'], right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_company = pd.read_json('company.json', typ='series', dtype='float')\n",
    "s_company.name = 'company_clean'\n",
    "df = pd.merge(df, s_company, how='left', left_on=['company'], right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bereinigen des DataFrames\n",
    "Im Laufe der Bearbeitung werden Sie einige Fehler in den Datensets finden. Bereinigen Sie diese am besten direkt nach dem importieren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Allgemeine Informationen\n",
    "* Schaue dir die Werteverteilung des DataFrames mit ``.describe()`` an um einen Überblick zu erhalten. Sollten die Zahlen nur in Wissenschaftlicher Schreibweise erscheinen schreibe in eine Zeile vorher: ``pd.options.display.float_format = '{:.2f}'.format`` um die Ausgabe von Pandas zu formatieren.\n",
    "* Wie viel unterschiedliche Taxifahrer gibt es in der Stadt?\n",
    "* Wie viele Taxiunternehmen gibt es und wie viele Taxifahrten wurden von den verschiedenen Taxis für die Unternehmen durchgeführt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Werteverteilung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finden Sie Extremwerte und filtern Sie diese ,soweit du sie schon erkennen kannst, heraus.\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wie viele verschiedene Taxifahrer gibt es in der Stadt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df['taxi_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wie viele Taxiunternehmen gibt es und wie viele Taxifahrten wurden von den verschiedenen Taxis für die Unternehmen durchgeführt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['company_clean', 'taxi_id']).size().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ergänzen der Informationen\n",
    "* Berechnen Sie die Gesamtkosten einer Fahrt und speichern Sie diese in einer Spalte mit dem Namen **trip_total**. <br>**Zusatz**: *Der Elegantere Weg nutzt die ``.sum()`` Funktion. Informieren Sie sich darüber was der ``axis=1`` der Parameter der ``.sum()`` Funktion bewirkt.*\n",
    "* Stellen Sie die Verteilung der Gesamteinnahmen als Boxplot und Violinplot dar\n",
    "* Berechnen Sie aus der Zeit und der Distanz die durchschnittliche Geschwindigkeit und speichern Sie diese iner einer neuen Spalte mit dem Namen **velo**\n",
    "* Untersuchen Sie die Grenzwerte der neu berechneten Spalten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gesamtkosten**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['trip_total'] = df['fare'] + df['tips'] + df['tolls'] + df['extras']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusatzübung\n",
    "df['trip_total'] = df[['fare', 'tips', 'tolls', 'extras']].sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gesamteinnahmen als Boxplot und Violinplot**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot \n",
    "df.boxplot(['trip_total'], showfliers=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Violinplot \n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "# Konvertieren der Serie in listen, da pyplot keine Serien unterstützt\n",
    "w = df['trip_total'].dropna().drop_duplicates().tolist()\n",
    "\n",
    "data=[w]\n",
    "\n",
    "ax.violinplot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Geschwindigkeit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['velo'] = df['trip_miles']/(df['trip_seconds']/3600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Untersuchung und Bereinigung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['velo'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ab diesen Zeitpunkt arbeiten wir mit der Geschwindigkeit. \n",
    "# Daher müssen alle unrealistischen Werte entfernt werden.\n",
    "df = df.dropna(subset=['velo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9997 Dollar für einen Taxitrip sind eher unwahrscheinlich. Solche Fahrten müssen überprüft werden.\n",
    "df['trip_total'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir setzen hier eine geschätze Grenze von 2000 für trip_total.\n",
    "df = df[df['trip_total'] < 2000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map Visualisation mit Leaflet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wir Datenpunkte auf einer Karte darstellen möchten, können wir die Bibliothek ipyleaflet benutzten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Konvertieren von Spalten in eine Liste\n",
    "Zunächst müssen wir allerdings lernen, wie man die Daten aus einem DataFrame in eine Liste umwandelt. Wir  möchten jetzt eine oder mehrer Spalten in eine Liste konvertieren in der keine NaN vorkommt.Wir erreichen dies mit dem folgenden Vorgehen:\n",
    "\n",
    "``df[['col_a', 'col_b',..].dropna().values.tolist()``\n",
    "\n",
    "Als Ergebnis sollten wir eine verschachtelte Liste erhalten:\n",
    "\n",
    "``[[.., .. ,..], ... ,[.., .. ,..]]``\n",
    "\n",
    "Probiere die Spalten eine Liste zu erzeugen die nur die Werte der Spalten **'pickup_latitude_clean'**, **'pickup_longitude_clean'** enthält."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lat_lon = df[['pickup_latitude_clean', 'pickup_longitude_clean']].dropna().values.tolist()\n",
    "lat_lon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iypleaflet - Daten auf Karten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probiere dich an den folgenden beiden Beispiele und versuche diese anzuwenden:\n",
    "* Heatmap: https://ipyleaflet.readthedocs.io/en/latest/api_reference/heatmap.html\n",
    "* Marker Cluster: https://ipyleaflet.readthedocs.io/en/latest/api_reference/marker_cluster.html\n",
    "\n",
    "* **Zusatz**: *Radius der Heatmap mit Schieberegeler einstellen*\n",
    "\n",
    "**Tipps**: Das Zentrum von Chicago hat folgende Koordinaten (41.87,-87.62). Als Zoomstufe hat sich 8 als guter Startwert herausgestellt. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Heatmap mit Leaflet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ipyleaflet.Map(center=(41.87,-87.62), zoom=10)\n",
    "\n",
    "\n",
    "heatmap = ipyleaflet.Heatmap(\n",
    "    locations=lat_lon,\n",
    "    radius=25\n",
    ")\n",
    "\n",
    "m.add_layer(heatmap);\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Marker Cluster** <br>\n",
    "Benutze die untenstehende Funktion um die Marker für das MarkerCluster zu erstellen. Du kannst als Parameter Size angeben, also wie viele Punkte aus dem Datenset verwendet werden sollen. Taste dich **vorsichtig heran, eine ``size>500`` solltest du nicht wählen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformationsfunktion\n",
    "def to_marker(lat_lon, size=50):\n",
    "    m = []\n",
    "    \n",
    "    for x in lat_lon[:size]:\n",
    "        m.append(ipyleaflet.Marker(location=list(x)))\n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = ipyleaflet.Map(center=(41.87,-87.62), zoom=10)\n",
    "    \n",
    "marker_list = to_marker(lat_lon)\n",
    "    \n",
    "marker_cluster = ipyleaflet.MarkerCluster(\n",
    "    markers=marker_list\n",
    ")\n",
    "\n",
    "m.add_layer(marker_cluster);\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auswertungen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zeitliche Auswertungen\n",
    "* Erstelle eine Spalte Tag und Uhrzeit. Zähle die Fahrten pro Tag im Monat und sortiere diese absteigend nach der Anzahl der Fahrten\n",
    "* Erstelle eine Plot eines Tages. \n",
    "<br>**Tipp:** Einen Tag als Datetime erstellst du mit ``datetime.date()``. Resample außerdem die Daten auf 1h Intervalle und berechne die Anzahl der Fahrten in diesem Zeitraum.\n",
    "\n",
    "* Erstelle eine Plot mit 3 Subplots in dem die Fahrten pro Tag, die Einnahmen pro Tag und die zurückgelegten Kilometer pro Tag analyisiert werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erstelle eine Spalte Tag und Uhrzeit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Day'] = pd.to_datetime(df['trip_start_timestamp'])\n",
    "df['Day'] = df['Day'].dt.date\n",
    "df['Day'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Time'] = pd.to_datetime(df['trip_start_timestamp'])\n",
    "df['Time'] = df['Time'].dt.time\n",
    "df['Time'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fahrten pro Tag im Monat, absteigend nach der Anzahl sortiert**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('Day').size().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erstelle eine Plot eines Tages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day = df[df['Day'] == datetime.date(2016, 1, 16)].copy()\n",
    "df_day['trip_start_timestamp'] = pd.to_datetime(df_day['trip_start_timestamp'])\n",
    "df_day.resample('1h', on='trip_start_timestamp').size().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3 Subplots in dem die Fahrten pro Tag, die Einnahmen pro Tag und die zurückgelegten Kilometer pro Tag**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_p_d = df[['Day']].groupby('Day').size()\n",
    "s_p_d.name = 'trips'\n",
    "s_p_d = s_p_d.to_frame()\n",
    "\n",
    "s_tt_d = df[['Day', 'trip_total']].groupby('Day').sum()\n",
    "s_km_d = df[['Day', 'trip_miles']].groupby('Day').sum()\n",
    "\n",
    "fig, ax = plt.subplots(3,1, figsize=(15, 6))\n",
    "s_p_d.plot(ax=ax[0])\n",
    "s_tt_d.plot(ax=ax[1])\n",
    "s_km_d.plot(ax=ax[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Companys\n",
    "* Lass dir die Companys und Ihrer Fahrer nach den Umsätzen der einzelnen Fahrer sortiert ausgeben\n",
    "* Berechne außerdem wie profitable die Fahrer waren, also wie viel Geld diese im Schnitt pro Kilometer eingenommen haben (inkl. Trinkgeld etc.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Companys (aufsteigend) und Ihrer Fahrer nach den Umsätzen der einzelnen Fahrer sortiert (absteigend) ausgeben**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_company_earning = df.groupby(['company_clean', 'taxi_id'])['trip_total'].sum().reset_index()\n",
    "df_company_earning.sort_values(['company_clean', 'trip_total'], ascending=[True, False]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Profitabilität der Fahrer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_company_earning = df.groupby(['company_clean', 'taxi_id'])['trip_total', 'trip_miles'].sum().reset_index()\n",
    "df_company_earning['earnings_per_miles'] = df_company_earning['trip_total']/df_company_earning['trip_miles']\n",
    "df_company_earning.sort_values('earnings_per_miles', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignorieren der Fehlerhaften inf Werte\n",
    "df_company_earning[df_company_earning['trip_miles'] != 0].sort_values('earnings_per_miles', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weitere Möglichkeiten der Datenanalyse\n",
    "Das Datenset bietet viele Möglichkeiten weitere Sachen zu erkunden. Spiele mit den Daten herum oder schaue dir neue Techniken an. Solltest du Anregungen brauchen schaue dir die Auswertung für eine Ähnliches Datenset aus New York an. Versuche einige Auswertung für Chicago durchzuführen.\n",
    "\n",
    "* Besonders Interessant ist hier die Sektion: Anomaly Detection<br> https://www.kaggle.com/fevsea/how-much-will-it-cost-me-pre-ride-regression#Exploratory-analysis-and-anomaly-detection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
